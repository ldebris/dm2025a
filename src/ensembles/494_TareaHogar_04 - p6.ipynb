{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldebris/dm2025a/blob/main/src/ensembles/494_TareaHogar_04%20-%20p6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cEmzeUKFkPh"
      },
      "source": [
        "# Tarea para el Hogar 04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSICPpyTGQmC"
      },
      "source": [
        "Esta Tarea para el Hogar 02 se entrega el final de la cuarta clase\n",
        "<br> se espera de usted que intente avanzar con los desafios propuestos y que los traiga terminados para la Clase 05 que será el viernes 01-agosto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DenyKXkiJ5JN"
      },
      "source": [
        "##  1. Cazatalentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-K2_ZsZGrVD"
      },
      "source": [
        "En la Clase 03 nos hemos enfrentado a  \"La Maldicion del Ganandor\",  elegir el modelo con el mejor puntaje simple no suele ser la mejor estrategia.\n",
        "<br> Lea y ejecute el notebook  **src/CazaTalentos/CazaTalentos.ipynb**\n",
        "<br> en caso de interesarle, participe del Desafío Ordenamiento  que vence el sábado 02 de agosto a las 19:00"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9GkTOk5J9t3"
      },
      "source": [
        "## 2. Hiperparámetros del LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmEFy0ukKL5T"
      },
      "source": [
        "Los objetivos de esta tarea son:\n",
        "\n",
        "\n",
        "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
        "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
        "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
        "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
        "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
        "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yvlS6JQLRMd"
      },
      "source": [
        "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
        "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eydI4YNAsFaf"
      },
      "source": [
        "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
        "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzU4S0SeMcpp"
      },
      "source": [
        "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
        "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
        "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNptUgI_NWWG"
      },
      "source": [
        "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
        "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
        "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
        "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
        "\n",
        "\n",
        "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
        "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpUThBojODyK"
      },
      "source": [
        "El desafío de esta tarea es:\n",
        "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
        "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
        "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX0qg_c0yqob"
      },
      "source": [
        "#### 2.1  Seteo del ambiente en Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LpZCst5a7Zs",
        "outputId": "d500808e-50b7-4d9c-f38d-c4820304e6f2",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/.drive\n"
          ]
        }
      ],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWLelftXa7Zt",
        "outputId": "3810f2b9-2809-4aab-c398-256645526c72",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/dm\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/dm\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/itba2025-8d0a/dataset_pequeno.csv\"\n",
        "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSKhZRToy2F7"
      },
      "source": [
        "### 2.2 Optimizacion Hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kwPpHAtSmix"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp4-Bj3aYI8d"
      },
      "source": [
        "### 2.2.1 Inicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy8YTZfESxeJ"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "gBq__iAdQliq",
        "outputId": "44a02fcf-cc63-4969-b268-a4c71edf05f0",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Tue Jul 29 12:11:47 PM 2025'"
            ],
            "text/markdown": "'Tue Jul 29 12:11:47 PM 2025'",
            "text/latex": "'Tue Jul 29 12:11:47 PM 2025'",
            "text/plain": [
              "[1] \"Tue Jul 29 12:11:47 PM 2025\""
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "7rdVrBojS1IV",
        "outputId": "47eed01b-861c-485a-89b0-fa8d91b5c871",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Ncells</th><td> 659554</td><td>35.3</td><td>1454468</td><td>77.7</td><td>1454468</td><td>77.7</td></tr>\n",
              "\t<tr><th scope=row>Vcells</th><td>1225547</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>1975128</td><td>15.1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 2 × 6 of type dbl\n\n| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n|---|---|---|---|---|---|---|\n| Ncells |  659554 | 35.3 | 1454468 | 77.7 | 1454468 | 77.7 |\n| Vcells | 1225547 |  9.4 | 8388608 | 64.0 | 1975128 | 15.1 |\n\n",
            "text/latex": "A matrix: 2 × 6 of type dbl\n\\begin{tabular}{r|llllll}\n  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n\\hline\n\tNcells &  659554 & 35.3 & 1454468 & 77.7 & 1454468 & 77.7\\\\\n\tVcells & 1225547 &  9.4 & 8388608 & 64.0 & 1975128 & 15.1\\\\\n\\end{tabular}\n",
            "text/plain": [
              "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
              "Ncells  659554 35.3 1454468    77.7 1454468  77.7\n",
              "Vcells 1225547  9.4 8388608    64.0 1975128  15.1"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuPfQ7ksjwW3"
      },
      "source": [
        "### 2.2.2 Carga de Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVyxLaJ1j1J_",
        "outputId": "bbfa32b7-bf73-405f-f9d6-7cfbf4e5abb4",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: data.table\n",
            "\n",
            "Loading required package: parallel\n",
            "\n",
            "Loading required package: primes\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘primes’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: primes\n",
            "\n",
            "Loading required package: rlist\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘rlist’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘XML’\n",
            "\n",
            "\n",
            "Loading required package: rlist\n",
            "\n",
            "Loading required package: yaml\n",
            "\n",
            "Loading required package: lightgbm\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘lightgbm’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: lightgbm\n",
            "\n",
            "Loading required package: DiceKriging\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘DiceKriging’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: DiceKriging\n",
            "\n",
            "Loading required package: mlrMBO\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘mlrMBO’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘fastmatch’, ‘RcppArmadillo’, ‘mlr’, ‘ParamHelpers’, ‘smoof’, ‘BBmisc’, ‘checkmate’, ‘lhs’, ‘parallelMap’\n",
            "\n",
            "\n",
            "Loading required package: mlrMBO\n",
            "\n",
            "Loading required package: mlr\n",
            "\n",
            "Loading required package: ParamHelpers\n",
            "\n",
            "Loading required package: smoof\n",
            "\n",
            "Loading required package: checkmate\n",
            "\n",
            "\n",
            "Attaching package: ‘checkmate’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:DiceKriging’:\n",
            "\n",
            "    checkNames\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"parallel\")\n",
        "\n",
        "if( !require(\"primes\") ) install.packages(\"primes\")\n",
        "require(\"primes\")\n",
        "\n",
        "if( !require(\"utils\") ) install.packages(\"utils\")\n",
        "require(\"utils\")\n",
        "\n",
        "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
        "require(\"rlist\")\n",
        "\n",
        "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
        "require(\"yaml\")\n",
        "\n",
        "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")\n",
        "\n",
        "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz-6Qt6BUaA3"
      },
      "source": [
        "### 2.2.3 Definicion de Parametros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOdlKd7lUm2I"
      },
      "source": [
        "aqui debe cargar SU semilla primigenia\n",
        "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASYkebOu2mF6",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM <- list()\n",
        "PARAM$experimento <- 4940\n",
        "PARAM$semilla_primigenia <- 100151\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezOhQdbA293o",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM$kaggle$competencia <- \"data-mining-analista-sr-2025-a\"\n",
        "PARAM$kaggle$cortes <- seq(10000, 12000, by= 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtB0Lub42rHO",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
        "# undersampling de 1.0  implica tomar TODOS los datos\n",
        "\n",
        "PARAM$trainingstrategy$undersampling <- 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFxm-xiNUOJX",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Parametros LightGBM\n",
        "\n",
        "PARAM$hyperparametertuning$xval_folds <- 5\n",
        "\n",
        "# parametros fijos del LightGBM que se pisaran con la parte variable de la BO\n",
        "PARAM$lgbm$param_fijos <-  list(\n",
        "  boosting= \"gbdt\", # puede ir  dart  , ni pruebe random_forest\n",
        "  objective= \"binary\",\n",
        "  metric= \"auc\",\n",
        "  first_metric_only= FALSE,\n",
        "  boost_from_average= TRUE,\n",
        "  feature_pre_filter= FALSE,\n",
        "  force_row_wise= TRUE, # para reducir warnings\n",
        "  verbosity= -100,\n",
        "\n",
        "  seed= PARAM$semilla_primigenia,\n",
        "\n",
        "  max_depth= 12L, # -1 significa no limitar,  por ahora lo dejo fijo\n",
        "  min_gain_to_split= 0.1388, # min_gain_to_split >= 0\n",
        "  min_sum_hessian_in_leaf= 0.001, #  min_sum_hessian_in_leaf >= 0.0\n",
        "  lambda_l1= 3.862, # lambda_l1 >= 0.0\n",
        "  lambda_l2= 4.542, # lambda_l2 >= 0.0\n",
        "  max_bin= 31L, # lo debo dejar fijo, no participa de la BO\n",
        "\n",
        "  bagging_fraction= 0.9239, # 0.0 < bagging_fraction <= 1.0\n",
        "  pos_bagging_fraction= 1.0, # 0.0 < pos_bagging_fraction <= 1.0\n",
        "  neg_bagging_fraction= 1.0, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  is_unbalance= FALSE, #\n",
        "  scale_pos_weight= 1.0, # scale_pos_weight > 0.0\n",
        "\n",
        "  drop_rate= 0.1, # 0.0 < neg_bagging_fraction <= 1.0\n",
        "  max_drop= 50, # <=0 means no limit\n",
        "  skip_drop= 0.5, # 0.0 <= skip_drop <= 1.0\n",
        "\n",
        "  extra_trees= FALSE,\n",
        "\n",
        "  num_iterations= 1200,\n",
        "  learning_rate= 0.012666,\n",
        "  feature_fraction= 0.8159,\n",
        "  num_leaves= 180,\n",
        "  min_data_in_leaf= 346\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Yj-JV4yvOt"
      },
      "source": [
        "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
        "<br> si es un numero entero debe ir  makeIntegerParam\n",
        "<br> si es un numero real (con decimales) debe ir  makeNumericParam\n",
        "<br> es muy importante leer cuales son un lower y upper  permitidos y ademas razonables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jENpR26ZyuS8",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
        "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
        "  makeIntegerParam(\"num_iterations\", lower= 300L, upper= 1500L),\n",
        "  makeNumericParam(\"learning_rate\", lower= 0.005, upper= 0.05),\n",
        "  makeNumericParam(\"feature_fraction\", lower= 0.6, upper= 0.95),\n",
        "  makeIntegerParam(\"num_leaves\", lower= 32L, upper= 200L),\n",
        "  makeIntegerParam(\"min_data_in_leaf\", lower= 200L, upper= 1000L)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_RPFUb3zMoW"
      },
      "source": [
        "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization\n",
        "<br> 30 es un valor muy tacaño, pero corre rápido\n",
        "<br> deberia partir de 50, alcanzando los 100 si se dispone de tiempo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5Rd3pnbzSiG",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "PARAM$hyperparametertuning$iteraciones <- 100 # iteraciones bayesianas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RWZXL1VZjMI"
      },
      "source": [
        "### 2.2.4  Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3toG9-lZm4K",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Ruta base donde querés guardar los experimentos\n",
        "base_path <- \"C:/Users/Luis/Documents/dm2025a-2\"\n",
        "\n",
        "# Crear carpeta del experimento\n",
        "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
        "experimento_path <- file.path(base_path, experimento_folder)\n",
        "\n",
        "# Crear las carpetas si no existen\n",
        "dir.create(experimento_path, showWarnings = FALSE, recursive = TRUE)\n",
        "\n",
        "# Cambiar al directorio del experimento\n",
        "setwd(experimento_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FM3lxKoLZ643",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# lectura del dataset\n",
        "\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsJ-91UeZ-I_",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "dataset_train <- dataset[foto_mes %in% c(202107)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrWE7BE0aB2J",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# paso la clase a binaria que tome valores {0,1}  enteros\n",
        "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
        "\n",
        "dataset_train[,\n",
        "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CAMBIO EL DATASET ORIGINAL COMO DATASET CUANTICO, AGREGO LAS LINEAS DE CODIGO PARA VER SI MEJORA EL AUC:**"
      ],
      "metadata": {
        "id": "8yvBmW-X1XD0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ucvUpXQ1qxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP7YlQBnaW6W",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# defino los datos que forma parte del training\n",
        "# aqui se hace el undersampling de los CONTINUA\n",
        "# notar que para esto utilizo la SEGUNDA semilla\n",
        "\n",
        "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
        "dataset_train[, azar := runif(nrow(dataset_train))]\n",
        "dataset_train[, training := 0L]\n",
        "\n",
        "dataset_train[\n",
        "  foto_mes %in% c(202107) &\n",
        "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
        "  training := 1L\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xElu4s5W4rX7",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# los campos que se van a utilizar\n",
        "\n",
        "campos_buenos <- setdiff(\n",
        "  colnames(dataset_train),\n",
        "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "PppMHcGYaaol",
        "outputId": "8184e8b0-baf8-440e-d293-4aa32c398ce1",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "83383"
            ],
            "text/markdown": "83383",
            "text/latex": "83383",
            "text/plain": [
              "[1] 83383"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "154"
            ],
            "text/markdown": "154",
            "text/latex": "154",
            "text/plain": [
              "[1] 154"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[training == 1L, clase01],\n",
        "  free_raw_data= FALSE\n",
        ")\n",
        "\n",
        "nrow(dtrain)\n",
        "ncol(dtrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta-EkOu3cphF"
      },
      "source": [
        "2.2.5 Configuracion Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjgfurjdfiXb",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# En el argumento x llegan los parmaetros de la bayesiana\n",
        "#  devuelve la AUC en cross validation del modelo entrenado\n",
        "\n",
        "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
        "\n",
        "  # x pisa (o agrega) a param_fijos\n",
        "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
        "\n",
        "  # entreno LightGBM\n",
        "  modelocv <- lgb.cv(\n",
        "    data= dtrain,\n",
        "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
        "    stratified= TRUE,\n",
        "    param= param_completo\n",
        "  )\n",
        "\n",
        "  # obtengo la ganancia\n",
        "  AUC <- modelocv$best_score\n",
        "\n",
        "  # hago espacio en la memoria\n",
        "  rm(modelocv)\n",
        "  gc(full= TRUE, verbose= FALSE)\n",
        "\n",
        "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
        "\n",
        "  return(AUC)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui comienza la configuracion de la Bayesian Optimization\n",
        "\n",
        "# en este archivo quedan la evolucion binaria de la BO\n",
        "kbayesiana <- \"bayesiana.RDATA\"\n",
        "\n",
        "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
        "\n",
        "configureMlr(show.learner.output= FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
        "  minimize= FALSE, # estoy Maximizando la ganancia\n",
        "  noisy= TRUE,\n",
        "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
        "  has.simple.signature= FALSE # paso los parametros en una lista\n",
        ")\n",
        "\n",
        "# cada 600 segundos guardo el resultado intermedio\n",
        "ctrl <- makeMBOControl(\n",
        "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
        "  save.file.path= kbayesiana\n",
        ") # se graba cada 600 segundos\n",
        "\n",
        "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "ctrl <- setMBOControlTermination(\n",
        "  ctrl,\n",
        "  iters= PARAM$hyperparametertuning$iteraciones\n",
        ") # cantidad de iteraciones\n",
        "\n",
        "# defino el método estandar para la creacion de los puntos iniciales,\n",
        "# los \"No Inteligentes\"\n",
        "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
        "\n",
        "# establezco la funcion que busca el maximo\n",
        "surr.km <- makeLearner(\n",
        "  \"regr.km\",\n",
        "  predict.type= \"se\",\n",
        "  covtype= \"matern3_2\",\n",
        "  control= list(trace= TRUE)\n",
        ")\n"
      ],
      "metadata": {
        "id": "_n18k1FpNsSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uUeVo5pc4zc"
      },
      "source": [
        "2.2.6 Corrida Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcABNaKGciaz",
        "outputId": "05cf5bbe-4cef-4e51-a2a0-41b25c8aeed1",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Computing y column(s) for design. Not provided.\n",
            "\n",
            "Tue Jul 29 12:49:13 PM 2025 AUC 0.931208746170165\n",
            "\n",
            "Tue Jul 29 12:51:26 PM 2025 AUC 0.929432223562552\n",
            "\n",
            "Tue Jul 29 12:53:23 PM 2025 AUC 0.929733308123539\n",
            "\n",
            "Tue Jul 29 12:55:12 PM 2025 AUC 0.928345498698645\n",
            "\n",
            "Tue Jul 29 12:58:42 PM 2025 AUC 0.929413041184317\n",
            "\n",
            "Tue Jul 29 12:59:55 PM 2025 AUC 0.930935087339146\n",
            "\n",
            "Tue Jul 29 01:02:19 PM 2025 AUC 0.929821728493793\n",
            "\n",
            "Tue Jul 29 01:03:58 PM 2025 AUC 0.930712221584491\n",
            "\n",
            "Tue Jul 29 01:06:01 PM 2025 AUC 0.929687911602767\n",
            "\n",
            "Tue Jul 29 01:09:00 PM 2025 AUC 0.930043082897761\n",
            "\n",
            "Tue Jul 29 01:09:53 PM 2025 AUC 0.929320004791824\n",
            "\n",
            "Tue Jul 29 01:12:20 PM 2025 AUC 0.929957343054265\n",
            "\n",
            "Tue Jul 29 01:14:21 PM 2025 AUC 0.928529600171991\n",
            "\n",
            "Tue Jul 29 01:15:42 PM 2025 AUC 0.923527353937325\n",
            "\n",
            "Tue Jul 29 01:17:59 PM 2025 AUC 0.929760132932694\n",
            "\n",
            "Tue Jul 29 01:19:45 PM 2025 AUC 0.929421969879114\n",
            "\n",
            "Tue Jul 29 01:21:36 PM 2025 AUC 0.929732218693867\n",
            "\n",
            "Tue Jul 29 01:22:52 PM 2025 AUC 0.928821322196256\n",
            "\n",
            "Tue Jul 29 01:24:02 PM 2025 AUC 0.924829691234697\n",
            "\n",
            "Tue Jul 29 01:27:09 PM 2025 AUC 0.92918555964352\n",
            "\n",
            "[mbo] 0: num_iterations=1130; learning_rate=0.0229; feature_fraction=0.687; num_leaves=99; min_data_in_leaf=748 : y = 0.931 : 152.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=1071; learning_rate=0.0277; feature_fraction=0.654; num_leaves=174; min_data_in_leaf=390 : y = 0.929 : 132.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=966; learning_rate=0.0324; feature_fraction=0.783; num_leaves=64; min_data_in_leaf=674 : y = 0.93 : 117.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=651; learning_rate=0.013; feature_fraction=0.798; num_leaves=91; min_data_in_leaf=764 : y = 0.928 : 108.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=1251; learning_rate=0.0113; feature_fraction=0.765; num_leaves=158; min_data_in_leaf=880 : y = 0.929 : 210.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=461; learning_rate=0.038; feature_fraction=0.87; num_leaves=142; min_data_in_leaf=517 : y = 0.931 : 73.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=1188; learning_rate=0.027; feature_fraction=0.861; num_leaves=76; min_data_in_leaf=914 : y = 0.93 : 143.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=777; learning_rate=0.0356; feature_fraction=0.688; num_leaves=138; min_data_in_leaf=687 : y = 0.931 : 99.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=1315; learning_rate=0.0397; feature_fraction=0.902; num_leaves=112; min_data_in_leaf=330 : y = 0.93 : 122.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=888; learning_rate=0.0155; feature_fraction=0.618; num_leaves=97; min_data_in_leaf=291 : y = 0.93 : 178.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=307; learning_rate=0.0244; feature_fraction=0.835; num_leaves=43; min_data_in_leaf=230 : y = 0.929 : 52.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=916; learning_rate=0.0198; feature_fraction=0.886; num_leaves=200; min_data_in_leaf=605 : y = 0.93 : 147.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=1380; learning_rate=0.0498; feature_fraction=0.81; num_leaves=132; min_data_in_leaf=979 : y = 0.929 : 121.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=572; learning_rate=0.00524; feature_fraction=0.723; num_leaves=151; min_data_in_leaf=836 : y = 0.924 : 81.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=1450; learning_rate=0.0466; feature_fraction=0.638; num_leaves=36; min_data_in_leaf=441 : y = 0.93 : 136.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=714; learning_rate=0.0301; feature_fraction=0.719; num_leaves=52; min_data_in_leaf=938 : y = 0.929 : 106.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=799; learning_rate=0.0451; feature_fraction=0.608; num_leaves=187; min_data_in_leaf=427 : y = 0.93 : 110.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=518; learning_rate=0.0412; feature_fraction=0.95; num_leaves=71; min_data_in_leaf=551 : y = 0.929 : 76.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=401; learning_rate=0.00888; feature_fraction=0.92; num_leaves=183; min_data_in_leaf=257 : y = 0.925 : 69.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_iterations=1382; learning_rate=0.0172; feature_fraction=0.742; num_leaves=117; min_data_in_leaf=575 : y = 0.929 : 187.5 secs : initdesign\n",
            "\n",
            "Saved the current state after iteration 1 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Jul 29 01:29:30 PM 2025 AUC 0.929617248819193\n",
            "\n",
            "[mbo] 1: num_iterations=923; learning_rate=0.0223; feature_fraction=0.698; num_leaves=101; min_data_in_leaf=733 : y = 0.93 : 140.0 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 01:30:48 PM 2025 AUC 0.930416046578746\n",
            "\n",
            "[mbo] 2: num_iterations=453; learning_rate=0.0355; feature_fraction=0.687; num_leaves=198; min_data_in_leaf=541 : y = 0.93 : 77.3 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 01:33:26 PM 2025 AUC 0.92992333409909\n",
            "\n",
            "[mbo] 3: num_iterations=1204; learning_rate=0.0227; feature_fraction=0.662; num_leaves=195; min_data_in_leaf=848 : y = 0.93 : 157.5 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 01:36:05 PM 2025 AUC 0.930638740527658\n",
            "\n",
            "[mbo] 4: num_iterations=1127; learning_rate=0.0195; feature_fraction=0.688; num_leaves=81; min_data_in_leaf=623 : y = 0.931 : 158.2 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 01:38:55 PM 2025 AUC 0.929933992455999\n",
            "\n",
            "[mbo] 5: num_iterations=1219; learning_rate=0.0232; feature_fraction=0.618; num_leaves=73; min_data_in_leaf=283 : y = 0.93 : 170.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 6 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Jul 29 01:41:36 PM 2025 AUC 0.929601725561843\n",
            "\n",
            "[mbo] 6: num_iterations=1110; learning_rate=0.0228; feature_fraction=0.63; num_leaves=99; min_data_in_leaf=969 : y = 0.93 : 159.9 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 01:43:56 PM 2025 AUC 0.929750859364053\n",
            "\n",
            "[mbo] 7: num_iterations=1263; learning_rate=0.0273; feature_fraction=0.681; num_leaves=110; min_data_in_leaf=885 : y = 0.93 : 139.4 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 01:46:16 PM 2025 AUC 0.930364956631962\n",
            "\n",
            "[mbo] 8: num_iterations=1156; learning_rate=0.0239; feature_fraction=0.766; num_leaves=97; min_data_in_leaf=449 : y = 0.93 : 140.1 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 01:47:42 PM 2025 AUC 0.929850937014045\n",
            "\n",
            "[mbo] 9: num_iterations=675; learning_rate=0.0372; feature_fraction=0.847; num_leaves=175; min_data_in_leaf=281 : y = 0.93 : 84.7 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 01:50:04 PM 2025 AUC 0.930122875244848\n",
            "\n",
            "[mbo] 10: num_iterations=1164; learning_rate=0.0231; feature_fraction=0.824; num_leaves=40; min_data_in_leaf=700 : y = 0.93 : 142.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 11 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Jul 29 01:51:14 PM 2025 AUC 0.929487245442871\n",
            "\n",
            "[mbo] 11: num_iterations=409; learning_rate=0.0376; feature_fraction=0.772; num_leaves=122; min_data_in_leaf=803 : y = 0.929 : 69.1 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 01:52:37 PM 2025 AUC 0.929281184334306\n",
            "\n",
            "[mbo] 12: num_iterations=481; learning_rate=0.0343; feature_fraction=0.947; num_leaves=138; min_data_in_leaf=525 : y = 0.929 : 82.6 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 01:55:50 PM 2025 AUC 0.929491755947683\n",
            "\n",
            "[mbo] 13: num_iterations=1257; learning_rate=0.0236; feature_fraction=0.604; num_leaves=108; min_data_in_leaf=715 : y = 0.929 : 192.3 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 01:56:58 PM 2025 AUC 0.929361265097797\n",
            "\n",
            "[mbo] 14: num_iterations=360; learning_rate=0.0381; feature_fraction=0.858; num_leaves=200; min_data_in_leaf=295 : y = 0.929 : 66.8 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 01:59:39 PM 2025 AUC 0.930868511915683\n",
            "\n",
            "[mbo] 15: num_iterations=1458; learning_rate=0.0234; feature_fraction=0.688; num_leaves=80; min_data_in_leaf=665 : y = 0.931 : 161.2 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:02:02 PM 2025 AUC 0.930205347587467\n",
            "\n",
            "[mbo] 16: num_iterations=1445; learning_rate=0.0325; feature_fraction=0.686; num_leaves=134; min_data_in_leaf=464 : y = 0.93 : 142.7 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 17 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Jul 29 02:03:08 PM 2025 AUC 0.929545915231982\n",
            "\n",
            "[mbo] 17: num_iterations=453; learning_rate=0.048; feature_fraction=0.807; num_leaves=135; min_data_in_leaf=472 : y = 0.93 : 65.2 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:05:22 PM 2025 AUC 0.930990735744403\n",
            "\n",
            "[mbo] 18: num_iterations=1135; learning_rate=0.0277; feature_fraction=0.683; num_leaves=186; min_data_in_leaf=740 : y = 0.931 : 132.9 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:07:39 PM 2025 AUC 0.929783011347926\n",
            "\n",
            "[mbo] 19: num_iterations=1138; learning_rate=0.0256; feature_fraction=0.717; num_leaves=102; min_data_in_leaf=733 : y = 0.93 : 136.7 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:10:16 PM 2025 AUC 0.930136823404171\n",
            "\n",
            "[mbo] 20: num_iterations=1320; learning_rate=0.023; feature_fraction=0.716; num_leaves=104; min_data_in_leaf=604 : y = 0.93 : 156.8 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:12:18 PM 2025 AUC 0.929985664642826\n",
            "\n",
            "[mbo] 21: num_iterations=787; learning_rate=0.0244; feature_fraction=0.686; num_leaves=191; min_data_in_leaf=582 : y = 0.93 : 121.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 22 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Jul 29 02:14:33 PM 2025 AUC 0.92948949078626\n",
            "\n",
            "[mbo] 22: num_iterations=1263; learning_rate=0.0333; feature_fraction=0.687; num_leaves=58; min_data_in_leaf=995 : y = 0.929 : 133.9 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:16:04 PM 2025 AUC 0.929879486897227\n",
            "\n",
            "[mbo] 23: num_iterations=637; learning_rate=0.0354; feature_fraction=0.879; num_leaves=97; min_data_in_leaf=722 : y = 0.93 : 90.8 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:18:36 PM 2025 AUC 0.929217323083027\n",
            "\n",
            "[mbo] 24: num_iterations=1449; learning_rate=0.0276; feature_fraction=0.689; num_leaves=103; min_data_in_leaf=809 : y = 0.929 : 151.5 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:21:03 PM 2025 AUC 0.930565609059389\n",
            "\n",
            "[mbo] 25: num_iterations=1206; learning_rate=0.0231; feature_fraction=0.685; num_leaves=63; min_data_in_leaf=446 : y = 0.931 : 145.7 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:23:03 PM 2025 AUC 0.930082714229063\n",
            "\n",
            "[mbo] 26: num_iterations=1099; learning_rate=0.0332; feature_fraction=0.687; num_leaves=199; min_data_in_leaf=654 : y = 0.93 : 120.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 27 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Jul 29 02:25:29 PM 2025 AUC 0.930782659256857\n",
            "\n",
            "[mbo] 27: num_iterations=1155; learning_rate=0.024; feature_fraction=0.796; num_leaves=186; min_data_in_leaf=690 : y = 0.931 : 144.6 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:28:17 PM 2025 AUC 0.929768127304659\n",
            "\n",
            "[mbo] 28: num_iterations=1402; learning_rate=0.0222; feature_fraction=0.682; num_leaves=155; min_data_in_leaf=732 : y = 0.93 : 167.6 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:29:53 PM 2025 AUC 0.930118227750469\n",
            "\n",
            "[mbo] 29: num_iterations=825; learning_rate=0.0378; feature_fraction=0.89; num_leaves=85; min_data_in_leaf=596 : y = 0.93 : 96.3 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:32:10 PM 2025 AUC 0.929856501842142\n",
            "\n",
            "[mbo] 30: num_iterations=1181; learning_rate=0.0286; feature_fraction=0.762; num_leaves=194; min_data_in_leaf=891 : y = 0.93 : 136.3 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:33:41 PM 2025 AUC 0.92898777922353\n",
            "\n",
            "[mbo] 31: num_iterations=643; learning_rate=0.0388; feature_fraction=0.678; num_leaves=198; min_data_in_leaf=949 : y = 0.929 : 90.2 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 32 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Jul 29 02:35:54 PM 2025 AUC 0.930122345942223\n",
            "\n",
            "[mbo] 32: num_iterations=1127; learning_rate=0.0266; feature_fraction=0.674; num_leaves=65; min_data_in_leaf=707 : y = 0.93 : 132.9 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:38:20 PM 2025 AUC 0.930722600998216\n",
            "\n",
            "[mbo] 33: num_iterations=1073; learning_rate=0.0267; feature_fraction=0.631; num_leaves=167; min_data_in_leaf=754 : y = 0.931 : 145.0 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:40:09 PM 2025 AUC 0.929240254463903\n",
            "\n",
            "[mbo] 34: num_iterations=721; learning_rate=0.0277; feature_fraction=0.662; num_leaves=198; min_data_in_leaf=758 : y = 0.929 : 108.6 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:42:32 PM 2025 AUC 0.930508964548067\n",
            "\n",
            "[mbo] 35: num_iterations=1110; learning_rate=0.0231; feature_fraction=0.707; num_leaves=158; min_data_in_leaf=678 : y = 0.931 : 142.4 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:44:48 PM 2025 AUC 0.929462180429357\n",
            "\n",
            "[mbo] 36: num_iterations=1108; learning_rate=0.025; feature_fraction=0.68; num_leaves=199; min_data_in_leaf=781 : y = 0.929 : 135.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 37 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Jul 29 02:47:01 PM 2025 AUC 0.929895380132235\n",
            "\n",
            "[mbo] 37: num_iterations=1500; learning_rate=0.0401; feature_fraction=0.808; num_leaves=193; min_data_in_leaf=746 : y = 0.93 : 132.5 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:48:36 PM 2025 AUC 0.928878025570976\n",
            "\n",
            "[mbo] 38: num_iterations=802; learning_rate=0.0386; feature_fraction=0.713; num_leaves=150; min_data_in_leaf=566 : y = 0.929 : 93.6 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:50:21 PM 2025 AUC 0.929514845879177\n",
            "\n",
            "[mbo] 39: num_iterations=898; learning_rate=0.0392; feature_fraction=0.636; num_leaves=197; min_data_in_leaf=311 : y = 0.93 : 105.3 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:51:32 PM 2025 AUC 0.929109264393446\n",
            "\n",
            "[mbo] 40: num_iterations=413; learning_rate=0.0411; feature_fraction=0.645; num_leaves=186; min_data_in_leaf=513 : y = 0.929 : 70.0 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:53:34 PM 2025 AUC 0.930045584109263\n",
            "\n",
            "[mbo] 41: num_iterations=1143; learning_rate=0.0346; feature_fraction=0.67; num_leaves=109; min_data_in_leaf=750 : y = 0.93 : 121.0 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:55:39 PM 2025 AUC 0.930544454095379\n",
            "\n",
            "[mbo] 42: num_iterations=864; learning_rate=0.0241; feature_fraction=0.684; num_leaves=180; min_data_in_leaf=749 : y = 0.931 : 124.7 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 43 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Jul 29 02:57:32 PM 2025 AUC 0.930124528855176\n",
            "\n",
            "[mbo] 43: num_iterations=1006; learning_rate=0.0326; feature_fraction=0.687; num_leaves=94; min_data_in_leaf=706 : y = 0.93 : 112.6 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 02:59:29 PM 2025 AUC 0.930037845573663\n",
            "\n",
            "[mbo] 44: num_iterations=1107; learning_rate=0.0356; feature_fraction=0.684; num_leaves=171; min_data_in_leaf=689 : y = 0.93 : 115.5 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:02:00 PM 2025 AUC 0.929844048290462\n",
            "\n",
            "[mbo] 45: num_iterations=1131; learning_rate=0.0215; feature_fraction=0.682; num_leaves=178; min_data_in_leaf=748 : y = 0.93 : 150.8 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:03:32 PM 2025 AUC 0.929608311458807\n",
            "\n",
            "[mbo] 46: num_iterations=753; learning_rate=0.0372; feature_fraction=0.87; num_leaves=186; min_data_in_leaf=562 : y = 0.93 : 91.0 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:05:41 PM 2025 AUC 0.929865515485227\n",
            "\n",
            "[mbo] 47: num_iterations=868; learning_rate=0.0234; feature_fraction=0.681; num_leaves=109; min_data_in_leaf=788 : y = 0.93 : 128.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 48 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Jul 29 03:07:56 PM 2025 AUC 0.929977484442695\n",
            "\n",
            "[mbo] 48: num_iterations=1097; learning_rate=0.0242; feature_fraction=0.829; num_leaves=95; min_data_in_leaf=751 : y = 0.93 : 134.2 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:09:43 PM 2025 AUC 0.928775677153565\n",
            "\n",
            "[mbo] 49: num_iterations=1162; learning_rate=0.0457; feature_fraction=0.738; num_leaves=142; min_data_in_leaf=633 : y = 0.929 : 106.6 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:12:08 PM 2025 AUC 0.929577336485395\n",
            "\n",
            "[mbo] 50: num_iterations=1387; learning_rate=0.0253; feature_fraction=0.832; num_leaves=104; min_data_in_leaf=202 : y = 0.93 : 144.3 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:13:24 PM 2025 AUC 0.929163001415536\n",
            "\n",
            "[mbo] 51: num_iterations=507; learning_rate=0.0378; feature_fraction=0.887; num_leaves=62; min_data_in_leaf=375 : y = 0.929 : 76.0 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:15:54 PM 2025 AUC 0.931276284933472\n",
            "\n",
            "[mbo] 52: num_iterations=1343; learning_rate=0.0248; feature_fraction=0.689; num_leaves=98; min_data_in_leaf=667 : y = 0.931 : 149.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 53 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Jul 29 03:18:32 PM 2025 AUC 0.930930206196812\n",
            "\n",
            "[mbo] 53: num_iterations=1384; learning_rate=0.0234; feature_fraction=0.679; num_leaves=95; min_data_in_leaf=698 : y = 0.931 : 156.9 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:21:04 PM 2025 AUC 0.930521463008486\n",
            "\n",
            "[mbo] 54: num_iterations=1385; learning_rate=0.0246; feature_fraction=0.72; num_leaves=186; min_data_in_leaf=630 : y = 0.931 : 151.5 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:22:20 PM 2025 AUC 0.930424828613546\n",
            "\n",
            "[mbo] 55: num_iterations=617; learning_rate=0.0423; feature_fraction=0.77; num_leaves=78; min_data_in_leaf=308 : y = 0.93 : 75.4 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:24:15 PM 2025 AUC 0.929907580830203\n",
            "\n",
            "[mbo] 56: num_iterations=1198; learning_rate=0.0409; feature_fraction=0.691; num_leaves=103; min_data_in_leaf=609 : y = 0.93 : 114.3 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:27:10 PM 2025 AUC 0.930898963485239\n",
            "\n",
            "[mbo] 57: num_iterations=1283; learning_rate=0.0172; feature_fraction=0.688; num_leaves=98; min_data_in_leaf=552 : y = 0.931 : 174.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 58 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Jul 29 03:28:04 PM 2025 AUC 0.929569033213131\n",
            "\n",
            "[mbo] 58: num_iterations=300; learning_rate=0.0288; feature_fraction=0.922; num_leaves=143; min_data_in_leaf=400 : y = 0.93 : 53.5 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:30:26 PM 2025 AUC 0.929617230225389\n",
            "\n",
            "[mbo] 59: num_iterations=1187; learning_rate=0.0248; feature_fraction=0.686; num_leaves=108; min_data_in_leaf=688 : y = 0.93 : 141.1 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:32:42 PM 2025 AUC 0.929684995544907\n",
            "\n",
            "[mbo] 60: num_iterations=1207; learning_rate=0.0275; feature_fraction=0.693; num_leaves=163; min_data_in_leaf=792 : y = 0.93 : 135.6 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:34:36 PM 2025 AUC 0.930586443298723\n",
            "\n",
            "[mbo] 61: num_iterations=1220; learning_rate=0.0406; feature_fraction=0.725; num_leaves=96; min_data_in_leaf=557 : y = 0.931 : 112.7 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:36:54 PM 2025 AUC 0.929410651916689\n",
            "\n",
            "[mbo] 62: num_iterations=1092; learning_rate=0.0244; feature_fraction=0.733; num_leaves=192; min_data_in_leaf=681 : y = 0.929 : 137.2 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:39:00 PM 2025 AUC 0.929323985415965\n",
            "\n",
            "[mbo] 63: num_iterations=869; learning_rate=0.0235; feature_fraction=0.683; num_leaves=97; min_data_in_leaf=840 : y = 0.929 : 126.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 64 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Jul 29 03:40:20 PM 2025 AUC 0.930076999102701\n",
            "\n",
            "[mbo] 64: num_iterations=671; learning_rate=0.0448; feature_fraction=0.795; num_leaves=153; min_data_in_leaf=632 : y = 0.93 : 79.0 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:42:15 PM 2025 AUC 0.930156206326306\n",
            "\n",
            "[mbo] 65: num_iterations=684; learning_rate=0.0236; feature_fraction=0.839; num_leaves=124; min_data_in_leaf=494 : y = 0.93 : 114.8 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:43:48 PM 2025 AUC 0.929350063868646\n",
            "\n",
            "[mbo] 66: num_iterations=873; learning_rate=0.0447; feature_fraction=0.708; num_leaves=153; min_data_in_leaf=866 : y = 0.929 : 92.2 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:46:06 PM 2025 AUC 0.929687475642971\n",
            "\n",
            "[mbo] 67: num_iterations=1345; learning_rate=0.029; feature_fraction=0.746; num_leaves=99; min_data_in_leaf=706 : y = 0.93 : 136.9 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:48:40 PM 2025 AUC 0.930391403856207\n",
            "\n",
            "[mbo] 68: num_iterations=1359; learning_rate=0.0245; feature_fraction=0.704; num_leaves=57; min_data_in_leaf=714 : y = 0.93 : 153.3 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:50:06 PM 2025 AUC 0.928413023322865\n",
            "\n",
            "[mbo] 69: num_iterations=538; learning_rate=0.0095; feature_fraction=0.727; num_leaves=47; min_data_in_leaf=272 : y = 0.928 : 85.7 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 70 in the file bayesiana.RDATA.\n",
            "\n",
            "Tue Jul 29 03:52:46 PM 2025 AUC 0.930510883151383\n",
            "\n",
            "[mbo] 70: num_iterations=1315; learning_rate=0.0211; feature_fraction=0.687; num_leaves=95; min_data_in_leaf=655 : y = 0.931 : 158.8 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:55:10 PM 2025 AUC 0.930812482849278\n",
            "\n",
            "[mbo] 71: num_iterations=1175; learning_rate=0.0241; feature_fraction=0.67; num_leaves=98; min_data_in_leaf=663 : y = 0.931 : 142.6 secs : infill_ei\n",
            "\n",
            "Tue Jul 29 03:57:33 PM 2025 AUC 0.929736109708743\n",
            "\n",
            "[mbo] 72: num_iterations=1212; learning_rate=0.026; feature_fraction=0.666; num_leaves=115; min_data_in_leaf=747 : y = 0.93 : 142.7 secs : infill_ei\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# inicio la optimizacion bayesiana, retomando si ya existe\n",
        "# es la celda mas lenta de todo el notebook\n",
        "\n",
        "if (!file.exists(kbayesiana)) {\n",
        "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
        "} else {\n",
        "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssk5nnMk6INK",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "d9a226cd-4012-46f7-c84f-5cf37d165e7a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'num_iterations'</li><li>'learning_rate'</li><li>'feature_fraction'</li><li>'num_leaves'</li><li>'min_data_in_leaf'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 'num\\_iterations'\n",
              "\\item 'learning\\_rate'\n",
              "\\item 'feature\\_fraction'\n",
              "\\item 'num\\_leaves'\n",
              "\\item 'min\\_data\\_in\\_leaf'\n",
              "\\item 'y'\n",
              "\\item 'dob'\n",
              "\\item 'eol'\n",
              "\\item 'error.message'\n",
              "\\item 'exec.time'\n",
              "\\item 'ei'\n",
              "\\item 'error.model'\n",
              "\\item 'train.time'\n",
              "\\item 'prop.type'\n",
              "\\item 'propose.time'\n",
              "\\item 'se'\n",
              "\\item 'mean'\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 'num_iterations'\n",
              "2. 'learning_rate'\n",
              "3. 'feature_fraction'\n",
              "4. 'num_leaves'\n",
              "5. 'min_data_in_leaf'\n",
              "6. 'y'\n",
              "7. 'dob'\n",
              "8. 'eol'\n",
              "9. 'error.message'\n",
              "10. 'exec.time'\n",
              "11. 'ei'\n",
              "12. 'error.model'\n",
              "13. 'train.time'\n",
              "14. 'prop.type'\n",
              "15. 'propose.time'\n",
              "16. 'se'\n",
              "17. 'mean'\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              " [1] \"num_iterations\"   \"learning_rate\"    \"feature_fraction\" \"num_leaves\"      \n",
              " [5] \"min_data_in_leaf\" \"y\"                \"dob\"              \"eol\"             \n",
              " [9] \"error.message\"    \"exec.time\"        \"ei\"               \"error.model\"     \n",
              "[13] \"train.time\"       \"prop.type\"        \"propose.time\"     \"se\"              \n",
              "[17] \"mean\"            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "colnames( tb_bayesiana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4zq-vknhjGc",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# almaceno los resultados de la Bayesian Optimization\n",
        "# y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "tb_bayesiana[, iter := .I]\n",
        "\n",
        "# ordeno en forma descendente por AUC = y\n",
        "setorder(tb_bayesiana, -y)\n",
        "\n",
        "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "fwrite( tb_bayesiana,\n",
        "  file= \"BO_log.txt\",\n",
        "  sep= \"\\t\"\n",
        ")\n",
        "\n",
        "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
        "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
        "  1, # el primero es el de mejor AUC\n",
        "  setdiff(colnames(tb_bayesiana),\n",
        "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
        "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
        "  with= FALSE\n",
        "]\n",
        "\n",
        "\n",
        "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8v2eA427N8e",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBTWexVU7PGC",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "5d079466-5231-4459-ef44-ea0613628f91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   num_iterations learning_rate feature_fraction num_leaves min_data_in_leaf\n",
            "            <int>         <num>            <num>      <int>            <int>\n",
            "1:           1571    0.03536802        0.3040041         18              114\n",
            "[1] 0.9316763\n"
          ]
        }
      ],
      "source": [
        "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
        "print(PARAM$out$lgbm$y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKsVZmAnhwX-"
      },
      "source": [
        "## 2.3  Produccion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ_C33Tr5B_9"
      },
      "source": [
        "### Final Training\n",
        "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDqfyA14hzwv",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# carpeta de trabajo en tu PC\n",
        "setwd(\"C:/Users/Luis/Documents/dm2025a-2/exp\")\n",
        "experimento <- paste0(\"exp\", PARAM$experimento)\n",
        "dir.create(experimento, showWarnings=FALSE)\n",
        "setwd(file.path(\"C:/Users/Luis/Documents/dm2025a-2/exp\", experimento))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qFmFivf5Iet"
      },
      "source": [
        "#### Final Training Dataset\n",
        "\n",
        "Aqui esta la gran decision de en qué meses hago el Final Training\n",
        "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lg5WVZncvc7H",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento <- paste0(\"exp\", PARAM$experimento)\n",
        "dir.create(experimento, showWarnings= FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc9QzXREv0xf",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# clase01\n",
        "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train <- dataset[foto_mes %in% c(202107)]"
      ],
      "metadata": {
        "id": "uRuJKjyqWPiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thjdqEBLuvNt",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[, clase01]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNUa-WSz5Oqu"
      },
      "source": [
        "#### Final Training Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgCcvBfEwImu",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "9cce009d-1ef7-48ee-d3e9-c962582ab5de"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$boosting</dt>\n",
              "\t\t<dd>'gbdt'</dd>\n",
              "\t<dt>$objective</dt>\n",
              "\t\t<dd>'binary'</dd>\n",
              "\t<dt>$metric</dt>\n",
              "\t\t<dd>'auc'</dd>\n",
              "\t<dt>$first_metric_only</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$boost_from_average</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$feature_pre_filter</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$force_row_wise</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$verbosity</dt>\n",
              "\t\t<dd>-100</dd>\n",
              "\t<dt>$seed</dt>\n",
              "\t\t<dd>100151</dd>\n",
              "\t<dt>$max_depth</dt>\n",
              "\t\t<dd>10</dd>\n",
              "\t<dt>$min_gain_to_split</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>$min_sum_hessian_in_leaf</dt>\n",
              "\t\t<dd>0.001</dd>\n",
              "\t<dt>$lambda_l1</dt>\n",
              "\t\t<dd>3.84</dd>\n",
              "\t<dt>$lambda_l2</dt>\n",
              "\t\t<dd>4.72</dd>\n",
              "\t<dt>$max_bin</dt>\n",
              "\t\t<dd>31</dd>\n",
              "\t<dt>$bagging_fraction</dt>\n",
              "\t\t<dd>0.86</dd>\n",
              "\t<dt>$pos_bagging_fraction</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$neg_bagging_fraction</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$is_unbalance</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$scale_pos_weight</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$drop_rate</dt>\n",
              "\t\t<dd>0.1</dd>\n",
              "\t<dt>$max_drop</dt>\n",
              "\t\t<dd>50</dd>\n",
              "\t<dt>$skip_drop</dt>\n",
              "\t\t<dd>0.5</dd>\n",
              "\t<dt>$extra_trees</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$num_iterations</dt>\n",
              "\t\t<dd>1571</dd>\n",
              "\t<dt>$learning_rate</dt>\n",
              "\t\t<dd>0.0353680153834145</dd>\n",
              "\t<dt>$feature_fraction</dt>\n",
              "\t\t<dd>0.304004082302477</dd>\n",
              "\t<dt>$num_leaves</dt>\n",
              "\t\t<dd>18</dd>\n",
              "\t<dt>$min_data_in_leaf</dt>\n",
              "\t\t<dd>114</dd>\n",
              "</dl>\n"
            ],
            "text/latex": [
              "\\begin{description}\n",
              "\\item[\\$boosting] 'gbdt'\n",
              "\\item[\\$objective] 'binary'\n",
              "\\item[\\$metric] 'auc'\n",
              "\\item[\\$first\\_metric\\_only] FALSE\n",
              "\\item[\\$boost\\_from\\_average] TRUE\n",
              "\\item[\\$feature\\_pre\\_filter] FALSE\n",
              "\\item[\\$force\\_row\\_wise] TRUE\n",
              "\\item[\\$verbosity] -100\n",
              "\\item[\\$seed] 100151\n",
              "\\item[\\$max\\_depth] 10\n",
              "\\item[\\$min\\_gain\\_to\\_split] 0\n",
              "\\item[\\$min\\_sum\\_hessian\\_in\\_leaf] 0.001\n",
              "\\item[\\$lambda\\_l1] 3.84\n",
              "\\item[\\$lambda\\_l2] 4.72\n",
              "\\item[\\$max\\_bin] 31\n",
              "\\item[\\$bagging\\_fraction] 0.86\n",
              "\\item[\\$pos\\_bagging\\_fraction] 1\n",
              "\\item[\\$neg\\_bagging\\_fraction] 1\n",
              "\\item[\\$is\\_unbalance] FALSE\n",
              "\\item[\\$scale\\_pos\\_weight] 1\n",
              "\\item[\\$drop\\_rate] 0.1\n",
              "\\item[\\$max\\_drop] 50\n",
              "\\item[\\$skip\\_drop] 0.5\n",
              "\\item[\\$extra\\_trees] FALSE\n",
              "\\item[\\$num\\_iterations] 1571\n",
              "\\item[\\$learning\\_rate] 0.0353680153834145\n",
              "\\item[\\$feature\\_fraction] 0.304004082302477\n",
              "\\item[\\$num\\_leaves] 18\n",
              "\\item[\\$min\\_data\\_in\\_leaf] 114\n",
              "\\end{description}\n"
            ],
            "text/markdown": [
              "$boosting\n",
              ":   'gbdt'\n",
              "$objective\n",
              ":   'binary'\n",
              "$metric\n",
              ":   'auc'\n",
              "$first_metric_only\n",
              ":   FALSE\n",
              "$boost_from_average\n",
              ":   TRUE\n",
              "$feature_pre_filter\n",
              ":   FALSE\n",
              "$force_row_wise\n",
              ":   TRUE\n",
              "$verbosity\n",
              ":   -100\n",
              "$seed\n",
              ":   100151\n",
              "$max_depth\n",
              ":   10\n",
              "$min_gain_to_split\n",
              ":   0\n",
              "$min_sum_hessian_in_leaf\n",
              ":   0.001\n",
              "$lambda_l1\n",
              ":   3.84\n",
              "$lambda_l2\n",
              ":   4.72\n",
              "$max_bin\n",
              ":   31\n",
              "$bagging_fraction\n",
              ":   0.86\n",
              "$pos_bagging_fraction\n",
              ":   1\n",
              "$neg_bagging_fraction\n",
              ":   1\n",
              "$is_unbalance\n",
              ":   FALSE\n",
              "$scale_pos_weight\n",
              ":   1\n",
              "$drop_rate\n",
              ":   0.1\n",
              "$max_drop\n",
              ":   50\n",
              "$skip_drop\n",
              ":   0.5\n",
              "$extra_trees\n",
              ":   FALSE\n",
              "$num_iterations\n",
              ":   1571\n",
              "$learning_rate\n",
              ":   0.0353680153834145\n",
              "$feature_fraction\n",
              ":   0.304004082302477\n",
              "$num_leaves\n",
              ":   18\n",
              "$min_data_in_leaf\n",
              ":   114\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "$boosting\n",
              "[1] \"gbdt\"\n",
              "\n",
              "$objective\n",
              "[1] \"binary\"\n",
              "\n",
              "$metric\n",
              "[1] \"auc\"\n",
              "\n",
              "$first_metric_only\n",
              "[1] FALSE\n",
              "\n",
              "$boost_from_average\n",
              "[1] TRUE\n",
              "\n",
              "$feature_pre_filter\n",
              "[1] FALSE\n",
              "\n",
              "$force_row_wise\n",
              "[1] TRUE\n",
              "\n",
              "$verbosity\n",
              "[1] -100\n",
              "\n",
              "$seed\n",
              "[1] 100151\n",
              "\n",
              "$max_depth\n",
              "[1] 10\n",
              "\n",
              "$min_gain_to_split\n",
              "[1] 0\n",
              "\n",
              "$min_sum_hessian_in_leaf\n",
              "[1] 0.001\n",
              "\n",
              "$lambda_l1\n",
              "[1] 3.84\n",
              "\n",
              "$lambda_l2\n",
              "[1] 4.72\n",
              "\n",
              "$max_bin\n",
              "[1] 31\n",
              "\n",
              "$bagging_fraction\n",
              "[1] 0.86\n",
              "\n",
              "$pos_bagging_fraction\n",
              "[1] 1\n",
              "\n",
              "$neg_bagging_fraction\n",
              "[1] 1\n",
              "\n",
              "$is_unbalance\n",
              "[1] FALSE\n",
              "\n",
              "$scale_pos_weight\n",
              "[1] 1\n",
              "\n",
              "$drop_rate\n",
              "[1] 0.1\n",
              "\n",
              "$max_drop\n",
              "[1] 50\n",
              "\n",
              "$skip_drop\n",
              "[1] 0.5\n",
              "\n",
              "$extra_trees\n",
              "[1] FALSE\n",
              "\n",
              "$num_iterations\n",
              "[1] 1571\n",
              "\n",
              "$learning_rate\n",
              "[1] 0.03536802\n",
              "\n",
              "$feature_fraction\n",
              "[1] 0.3040041\n",
              "\n",
              "$num_leaves\n",
              "[1] 18\n",
              "\n",
              "$min_data_in_leaf\n",
              "[1] 114\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
        "  PARAM$out$lgbm$mejores_hiperparametros)\n",
        "\n",
        "param_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZIYn4l95TBH"
      },
      "source": [
        "#### Training\n",
        "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPLsd4mMRe4u",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
        "\n",
        "param_normalizado <- copy(param_final)\n",
        "param_normalizado$min_data_in_leaf <-  param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRI_-taRwOXO",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "  # entreno LightGBM\n",
        "\n",
        "  modelo_final <- lgb.train(\n",
        "    data= dtrain,\n",
        "    param= param_normalizado\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bkhnCvj0g3Q",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# ahora imprimo la importancia de variables\n",
        "\n",
        "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
        "archivo_importancia <- \"impo.txt\"\n",
        "\n",
        "fwrite(tb_importancia,\n",
        "  file= archivo_importancia,\n",
        "  sep= \"\\t\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ3sLmbh0kFj",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
        "\n",
        "lgb.save(modelo_final, \"modelot5.txt\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEtp2--t5Ymg"
      },
      "source": [
        "### Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI5008Mj5ZdI"
      },
      "source": [
        "Aplico el modelo final a los datos del futuro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PimBY3N_0ryP",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# aplico el modelo a los datos sin clase\n",
        "dfuture <- dataset[foto_mes == 202109]\n",
        "\n",
        "# aplico el modelo a los datos nuevos\n",
        "prediccion <- predict(\n",
        "  modelo_final,\n",
        "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D26rNRh55gpw"
      },
      "source": [
        "#### Tabla Prediccion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJwg7LHd11yu",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# tabla de prediccion\n",
        "\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "tb_prediccion[, prob := prediccion ]\n",
        "\n",
        "# grabo las probabilidad del modelo\n",
        "fwrite(tb_prediccion,\n",
        "  file= \"prediccion.txt\",\n",
        "  sep= \"\\t\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOt4eG_55ltv"
      },
      "source": [
        "Kaggle Competition Submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWW3tatE12je",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "9824c89a-eb20-404b-89de-3e5d765bdbc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in system(linea, intern = TRUE):\n",
            "\"running command 'kaggle competitions submit -c data-mining-analista-sr-2025-a -f ./kaggle/KA4940_10000.csv -m 'envios=10000  semilla=100151'' had status 1\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/competitions/submission-url \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in system(linea, intern = TRUE):\n",
            "\"running command 'kaggle competitions submit -c data-mining-analista-sr-2025-a -f ./kaggle/KA4940_10500.csv -m 'envios=10500  semilla=100151'' had status 1\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/competitions/submission-url \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in system(linea, intern = TRUE):\n",
            "\"running command 'kaggle competitions submit -c data-mining-analista-sr-2025-a -f ./kaggle/KA4940_11000.csv -m 'envios=11000  semilla=100151'' had status 1\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/competitions/submission-url \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in system(linea, intern = TRUE):\n",
            "\"running command 'kaggle competitions submit -c data-mining-analista-sr-2025-a -f ./kaggle/KA4940_11500.csv -m 'envios=11500  semilla=100151'' had status 1\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/competitions/submission-url \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning message in system(linea, intern = TRUE):\n",
            "\"running command 'kaggle competitions submit -c data-mining-analista-sr-2025-a -f ./kaggle/KA4940_12000.csv -m 'envios=12000  semilla=100151'' had status 1\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/competitions/submission-url \n"
          ]
        }
      ],
      "source": [
        "# genero archivos con los  \"envios\" mejores\n",
        "# suba TODOS los archivos a Kaggle\n",
        "\n",
        "# ordeno por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)\n",
        "\n",
        "dir.create(\"kaggle\")\n",
        "\n",
        "for (envios in PARAM$kaggle$cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
        "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
        "\n",
        "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
        "\n",
        "  # grabo el archivo\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "    file= archivo_kaggle,\n",
        "    sep= \",\"\n",
        "  )\n",
        "\n",
        "  # subida a Kaggle, armo la linea de comando\n",
        "  comando <- \"kaggle competitions submit\"\n",
        "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
        "  arch <- paste( \"-f\", archivo_kaggle)\n",
        "\n",
        "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
        "  \"  semilla=\", PARAM$semilla_primigenia,\n",
        "    \"'\" )\n",
        "\n",
        "  linea <- paste( comando, competencia, arch, mensaje)\n",
        "\n",
        "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
        "  cat(salida, \"\\n\")\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9tB2X4439Hg",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zA_W25c15DP",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "55c1e948-4585-4637-f888-c1913ed38db6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "'Tue Jul 29 12:05:45 AM 2025'"
            ],
            "text/latex": [
              "'Tue Jul 29 12:05:45 AM 2025'"
            ],
            "text/markdown": [
              "'Tue Jul 29 12:05:45 AM 2025'"
            ],
            "text/plain": [
              "[1] \"Tue Jul 29 12:05:45 AM 2025\""
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdVZucdLHzZ0"
      },
      "source": [
        "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar04**\n",
        "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMHh7uNVIJkT",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}